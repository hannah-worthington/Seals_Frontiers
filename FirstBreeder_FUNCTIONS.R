### Likelihood function

# Name: likelihood_breeder
# Objective: To evaluate the negative log-likelihood of the multiple cohort HMM with first-time breeder survival given a set of parameter values and capture histories
# Inputs: param - model specific, will be passed to unpack_param_breeder function for structuring
#         X - capture histories, a matrix for each cohort stored in a list
#         arr.dist - distribution on arrivals, 'normal' or 'lognormal'
#         arr.str - structure for arrivals (shared or cohort), list over parameters of chosen distribution
#         min.age - minimum age of return (default = 3)
# Outputs: lik - negative log-likelihood value

likelihood_breeder <- function(param, X, arr.dist, arr.str, min.age = 3)  {
  
  # print(param)
  
  # define constants
  n.cohorts <- length(X)  # number of cohorts
  n <- rep(0, n.cohorts)  # number of individuals in each cohort
  K <- rep(0, n.cohorts)  # number of capture occasions for each cohort
  for (c in 1:n.cohorts)  {
    n[c] <- length(data[[c]][,1])
    K[c] <- length(data[[c]][1,])
  }
  
  # unpack the parameter vector
  params <- unpack_param_breeder(param, arr.dist, arr.str, min.age, n.cohorts, K)
  HMM <- HMM_str_breeder(params, n.cohorts, K)
  
  # storage variables
  lik.cohort <- rep(0, n.cohorts)
  
  # loop over cohorts evaluating likelihood for single cohort
  for (c in 1:n.cohorts)  {
    lik.partial <- 0
    # loop over individuals
    for (i in 1:n[c])  {
      contrib <- HMM$pione[[c]]
      # loop over occasions
      for (k in 1:K[c])  {
        contrib <- contrib %*% HMM$gamma[[c]][,,k]
        contrib <- contrib %*% HMM$pmat[[c]][,,X[[c]][i,k]+1, k]
      }
      # individual contribution
      contrib <- contrib %*% matrix(1, nrow = 4, ncol = 1)
      # add to likelihood for this cohort if nonzero
      if (contrib > 0)  {
        lik.partial <- lik.partial + log(contrib)
      } else if (contrib == 0)  {
        lik.partial <- lik.partial - 10000
      }
    }
    # store likelihood value for cohort, checking for nonzero
    lik.cohort[c] <- lik.partial
  }
  
  # evaluate full likelihood
  lik <- -sum(lik.cohort)
  
  # return
  return(lik)
}



### Function to return the HMM structures

# Name: HMM_str_breeder
# Objective: To take a list of parameters returned from the arr.dist functions and return the HMM structures for use in the likelihood
# Inputs: param - list of parameters generated by the unpack_param_breeder function
#         n.cohorts - the number of cohorts
#         K - number of capture occasions for each cohort
# Outputs: pione - initial state distributions for each cohort
#          gamma - transition probability matrices for each cohort
#          pmat - observation matrices for each cohort

HMM_str_breeder <- function(param, n.cohorts, K)  {
  
  # initial state probabilities
  # state probabilities at time 0, year of tagging
  pione <- list()
  for (c in 1:n.cohorts)  {
    pione[[c]] <- c(1, 0, 0, 0)
  }
  
  # transition probability matrices (state, state, occasion)
  gamma <- list()
  for (c in 1:n.cohorts)  {
    gamma[[c]] <- array(0, dim = c(4, 4, K[c]))
    gamma[[c]][1,1,] <- 1 - param$betastar[[c]]
    gamma[[c]][1,2,] <- param$betastar[[c]]
    gamma[[c]][2,3,] <- param$phi[1]
    gamma[[c]][2,4,] <- 1 - param$phi[1]
    gamma[[c]][3,3,] <- param$phi[2]
    gamma[[c]][3,4,] <- 1-param$phi[2]
    gamma[[c]][4,4,] <- 1
  }
  
  # observation matrices (state, state, capture/not, occasion)
  pmat <- list()
  for (c in 1:n.cohorts)  {
    pmat[[c]] <- array(0, dim = c(4, 4, 2, K[c]))
    pmat[[c]][1,1,1,] <- 1
    pmat[[c]][2,2,1,] <- 1-param$p[[c]]
    pmat[[c]][3,3,1,] <- 1-param$p[[c]]
    pmat[[c]][4,4,1,] <- 1
    pmat[[c]][2,2,2,] <- param$p[[c]]
    pmat[[c]][3,3,2,] <- param$p[[c]]
  }
  
  # return
  return(list('pione' = pione, 'gamma' = gamma, 'pmat' = pmat))
}



### Function to unpack the parameter vector
### Options: normal distribution(s) on arrivals, constant capture, constant first-time breeder survival, constant return breeder survival
### Options: log-normal distribution(s) on arrivals, constant capture, constant first-time breeder survival, constant return breeder survival

# Name: unpack_param_breeder
# Objective: To unpack and transform a vector of parameter values for the cohort stopover HMM with first-time breeder survival model
# Inputs: param - vector of parameter values, model dependent:
#               - For normal distribution(s): arrival distribution parameters (mean(s) (log), sd(s) (log), w (mixture parameter(s), logit))
#               - For log-normal distribution(s): arrival distribution parameters (mean(s), sd(s) (log), w (mixture parameter(s), logit))
#               - capture probability (logit)
#               - survival probabilities (first-time breeder, return breeder) (logit)
#         arr.dist - distribution, 'normal' or 'lognormal'
#         arr.str - arrivals structure, shared or cohort specific (list with vector for each of mean, sd, w (when required) for both normal and log-normal)
#         min.age - minimum age of return
#         n.cohorts - number of cohorts
#         K - number of capture occasions for each cohort
# Outputs: mu - mean(s) of arrival distribution for each cohort
#          sd - sd(s) of arrival distribution for each cohort
#          w - mixture proportion for first mixture (1 for single distribution)
#          beta - arrival probabilities for each cohort
#          betastar - conditional arrival probabilities for each cohort
#          p - capture probability, time structured to permit structural zeros
#          phi- survival probabilities (first-time breeder, return breeder)

unpack_param_breeder <- function(param, arr.dist, arr.str, min.age, n.cohorts, K)  {
  
  # number of mixtures taken from length of first object in arr.str list
  n.mixtures <- length(arr.str[[1]])
  
  # storage
  means <- matrix(0, nrow = n.mixtures, ncol = n.cohorts)
  sds <- matrix(0, nrow = n.mixtures, ncol = n.cohorts)
  w <- matrix(0, nrow = n.mixtures - 1, ncol = n.cohorts)
  res <- list()
  names <- c()
  
  # mean(s) of arrival distributions for normal distribution(s)
  if (arr.dist == 'normal')  {
    for (m in 1:n.mixtures)  {
      names <- c(names, paste('mu', m, sep = ''))
      if (arr.str[[1]][m] == 'shared')  {
        mean <- exp(param[1])
        means[m,] <- rep(mean, n.cohorts)
        param <- param[-1]
      } else if (arr.str[[1]][m] == 'cohort')  {
        mean <- exp(param[1:n.cohorts])
        means[m,] <- mean
        param <- param[-(1:n.cohorts)]
      }
      res <- c(res, list(mean))
    }
  }
  
  # mean(s) of arrival distributions for log-normal distribution(s)
  if (arr.dist == 'lognormal')  {
    for (m in 1:n.mixtures)  {
      names <- c(names, paste('mu', m, sep = ''))
      if (arr.str[[1]][m] == 'shared')  {
        mean <- param[1]
        means[m,] <- rep(mean, n.cohorts)
        param <- param[-1]
      } else if (arr.str[[1]][m] == 'cohort')  {
        mean <- param[1:n.cohorts]
        means[m,] <- mean
        param <- param[-(1:n.cohorts)]
      }
      res <- c(res, list(mean))
    }
  }
  
  # sd of arrival distributions
  for (m in 1:n.mixtures)  {
    names <- c(names, paste('sd', m, sep = ''))
    if (arr.str[[2]][m] == 'shared')  {
      sd <- exp(param[1])
      sds[m,] <- rep(sd, n.cohorts)
      param <- param[-1]
    } else if (arr.str[[2]][m] == 'cohort')  {
      sd <- exp(param[1:n.cohorts])
      sds[m,] <- sd
      param <- param[-(1:n.cohorts)]
    }
    res <- c(res, list(sd))
  }
  
  # mixture proportions if needed
  if (n.mixtures >= 2)  {
    for (m in 1:(n.mixtures - 1))  {
      names <- c(names, paste('w', m, sep = ''))
      if (arr.str[[3]][m] == 'shared')  {
        mix <- 1/(1 + exp(-param[1]))
        w[m,] <- rep(mix, n.cohorts)
        param <- param[-1]
      } else if (arr.str[[3]][m] == 'cohort')  {
        mix <- 1/(1 + exp(-param[1:n.cohorts]))
        w[m,] <- mix
        param <- param[-(1:n.cohorts)]
      }
      res <- c(res, list(mix))
    }
  } else if (n.mixtures == 1)  {
    w <- 1
  }
  
  # arrival probabilities
  beta <- list()
  text.cohorts <- ifelse(n.mixtures == 1, 'one', 'two')
  beta_fun <- match.fun(paste(text.cohorts, arr.dist, 'betas', sep=''))
  for (c in 1:n.cohorts)  {
    if (n.mixtures == 1)  {
      beta[[c]] <- beta_fun(mu = means[,c], sd = sds[,c], K = K[c], min.age = min.age)
    } else if (n.mixtures == 2)  {
      beta[[c]] <- beta_fun(mu = means[,c], sd = sds[,c], w = w[,c], K = K[c], min.age = min.age)
    }
  }
  
  # conditional arrival probabilities
  betastar <- list()
  for (c in 1:n.cohorts)  {
    betastar[[c]] <- rep(0, K[c])
    for (k in 1:K[c])  {
      if (sum(beta[[c]][k:K[c]]) > 0)  {
        betastar[[c]][k] <- beta[[c]][k]/sum(beta[[c]][k:K[c]])
      }
    }
  }
  
  # capture probability (constant)
  pnonzero <- 1/(1 + exp(-param[1]))
  param <- param[-1]
  names <- c(names, 'p')
  res <- c(res, list(pnonzero))
  p <- list()
  for (c in 1:n.cohorts)  {
    p[[c]] <- rep(0, K[c])
    p[[c]][min.age:K[c]] <- pnonzero
  }
  
  # retention probability (constant)
  phi <- 1/(1 + exp(-param))
  names <- c(names, 'phi')
  res <- c(res, list(phi))
  
  # add names to parameter list
  names(res) <- names
  
  # return all parameters
  return(c(list('mu' = means, 'sd' = sds, 'w' = w, 'beta' = beta, 'betastar' = betastar, 'p' = p, 'phi' = phi), 'values' = list(res)))
}




### Functions to calculate arrival probabilities

### Function to calculate beta probabilities from a normal distribution over the plausible recruitment ages

# Name: onenormalbetas
# Objective: To calculate the beta probabilities from a truncated normal distribution
# Inputs: mu - mean of the arrival distribution
#         sd - sd of the arrival distribution
#         K - number of occasions
#         min.age - minimum age of return
# Outputs: beta - set of beta parameters

onenormalbetas <- function(mu, sd, K, min.age)  {
  
  # storage
  beta <- rep(0, K)
  
  # integrate to find probabilities
  for (k in min.age:K)  {
    beta[k] <- pnorm(k + 0.5, mu, sd) - pnorm(k - 0.5, mu, sd)
  }
  
  # truncating, so reweight the probabilities checking that they are nonzero
  truncate <- pnorm(K + 0.5, mu, sd) - pnorm(min.age - 0.5, mu, sd)
  if (truncate > 0)  {
    beta <- beta/truncate
  } else if (truncate == 0 & mu < 0)  {
    beta[1] <- 1
  } else if (truncate == 0 & mu > K)  {
    beta[K] <- 1
  }
  
  # return the beta probabilities
  return(beta)
}



### Function to calculate beta probabilities from a log-normal distribution over the plausible recruitment ages

# Name: onelognormalbetas
# Objective: To calculate the beta probabilities from a truncated log-normal distribution
# Inputs: mu - mean of the arrival distribution (log-scale)
#         sd - sd of the arrival distribution (log-scale)
#         K - number of occasions
#         min.age - minimum age of return
# Outputs: beta - set of beta parameters

onelognormalbetas <- function(mu, sd, K, min.age)  {
  
  # storage
  beta <- rep(0, K)
  
  # integrate to find probabilities
  for (k in min.age:K)  {
    beta[k] <- plnorm(k + 0.5, mu, sd) - plnorm(k - 0.5, mu, sd)
  }
  
  # truncating, so reweight the probabilities checking that they are nonzero
  truncate <- plnorm(K + 0.5, mu, sd) - plnorm(min.age - 0.5, mu, sd)
  if (truncate > 0)  {
    beta <- beta/truncate
  } else if (truncate == 0 & mu < 0)  {
    beta[1] <- 1
  } else if (truncate == 0 & mu > K)  {
    beta[K] <- 1
  }
  
  # return the beta probabilities
  return(beta)
}



### Function to calculate beta probabilities from a mixture of two normal distributions over the plausible recruitment ages

# Name: twonormalbetas
# Objective: To calculate the beta probabilities from a mixture of two truncated normal distributions
# Inputs: mu - means vector for the two normals that form the arrival distribution
#         sd - sds vector for the two normals that form the arrival distribution
#         w - mixture proportion for distribution 1
#         K - number of occasions
#         min.age - minimum age of return
# Outputs: beta - set of beta parameters

twonormalbetas <- function(mu, sd, w, K, min.age)  {
  
  # find the separate truncated mixture distributions
  mix.1 <- onenormalbetas(mu[1], sd[1], K, min.age)
  mix.2 <- onenormalbetas(mu[2], sd[2], K, min.age)
  
  # create mixture
  beta <- w*mix.1 + (1-w)*mix.2
  
  # check the probabilities sum to one
  total <- sum(beta)
  if (total > 0)  {
    beta <- beta/total
  } 
  
  # return the beta probabilities
  return(beta)
}



### Function to calculate beta probabilities from a mixture of two log-normal distributions over the plausible recruitment ages

# Name: twolognormalbetas
# Objective: To calculate the beta probabilities from a mixture of two truncated log-normal distributions
# Inputs: mu - means vector for the two log-normals that form the arrival distribution
#         sd - sds vector for the two log-normals that form the arrival distribution
#         w - mixture proportion for distribution 1
#         K - number of occasions
#         min.age - minimum age of return
# Outputs: beta - set of beta parameters

twolognormalbetas <- function(mu, sd, w, K, min.age)  {
  
  # find the separate truncated mixture distributions
  mix.1 <- onelognormalbetas(mu[1], sd[1], K, min.age)
  mix.2 <- onelognormalbetas(mu[2], sd[2], K, min.age)
  
  # create mixture
  beta <- w*mix.1 + (1-w)*mix.2
  
  # check the probabilities sum to one
  total <- sum(beta)
  if (total > 0)  {
    beta <- beta/total
  }
  
  # return the beta probabilities
  return(beta)
}



### Bootstrap cohort histories

# Name: bootstrap_data
# Objective: To bootstrap the capture histories from multiple cohorts maintaining the number of animals per cohort
# Inputs: X - list of cohort capture histories
#         n.cohorts - number of cohorts
#         n - vector of number of individuals in each cohort
# Outputs: X - list of bootstrapped cohorts

bootstrap_data <- function(X, n.cohorts, n)  {
  
  # storage
  bootX <- list()
  
  # for each cohort
  for (c in 1:n.cohorts)  {
    
    # bootstrap individuals
    bootsamp <- sample(1:n[c], n[c], replace = T)
    
    # add bootstrapped histories
    boothist <- X[[c]][bootsamp,]
    
    # add cohort to list
    bootX[[c]] <- boothist
  }
  
  # return
  return(bootX)
}



### bootstrap for confidence intervals

# Name: bootstrap_fn
# Objective: To generate bootstrap estimates and confidence intervals for results and plotting
# Inputs: nboot - number of bootstraps to perform
#         param - starting values for the optimiser
#         X - capture histories
#         arr.dist - distribution for arrivals
#         arr.str - model structure for arrival distribution
#         min.age - minimum age of recruitment
#         alpha - significance level (default 0.05)
# Outputs: CIs - bootstrap confidence intervals for all model parameters
#          betas - plotting values for arrival distribution

bootstrap_fn <- function(nboot, param, X, arr.dist, arr.str, min.age = 3, alpha = 0.05)  {
  
  # define constants
  n.cohorts <- length(X)  # number of cohorts
  n <- rep(0, n.cohorts)  # number of individuals in each cohort
  K <- rep(0, n.cohorts)  # number of capture occasions in each cohort
  for (c in 1:n.cohorts)  {
    n[c] <- length(data[[c]][,1])
    K[c] <- length(data[[c]][1,])
  }
  n.mixtures <- length(arr.str[[1]])
  
  # storage
  # bootres <- matrix(0, nrow = nboot + 1, ncol = length(param))
  bootCI <- list()
  betaCI <- list()
  
  # optimise original data
  opt <- nlm(likelihood_cohort, param, X = X, arr.dist = arr.dist, arr.str = arr.str)
  while (opt$iterations == 100)  {
    opt <- nlm(likelihood_cohort, opt$estimate, X = data, arr.dist = arr.dist, arr.str = arr.str)
  }
  # bootres[1,] <- opt$estimate
  unpack <- unpack_param(opt$estimate, arr.dist, arr.str, min.age, n.cohorts, K)
  values <- unpack$values
  beta <- unpack$beta
  
  # run bootstrap
  for (b in 1:nboot)  {
    print(paste('bootstrap', b))
    
    # generate data
    bootdata <- bootstrap_data(X, n.cohorts, n)
    
    # maximise likelihood
    bootopt <- nlm(likelihood_cohort, opt$estimate, X = bootdata, arr.dist = arr.dist, arr.str = arr.str)
    
    # check convergence
    while (bootopt$iterations == 100)  {
      bootopt <- nlm(likelihood_cohort, bootopt$estimate, X = bootdata, arr.dist = arr.dist, arr.str = arr.str)
    }
    
    # store results
    # bootres[b + 1,] <- bootopt$estimate
    # write.table(bootres, 'bootres.txt', col.names = F, row.names = F)
    
    # unpack the estimates and store
    unpack.boot <- unpack_param(bootopt$estimate, arr.dist, arr.str, min.age, n.cohorts, K)
    for (i in 1:length(values))  {
      values[[i]] <- rbind(values[[i]], unpack.boot$values[[i]])
    }
    for (c in 1:n.cohorts)  {
      beta[[c]] <- rbind(beta[[c]], unpack.boot$beta[[c]])
    }
  }
  
  # find confidence intervals
  for (i in 1:length(values)) {
    bootCI[[i]] <- apply(values[[i]], 2, quantile, probs = c(alpha/2, 1 - (alpha/2)))
  }
  names(bootCI) <- names(values)
  for (c in 1:n.cohorts)  {
    betaCI[[c]] <- apply(beta[[c]], 2, quantile, probs = c(alpha/2, 1 - (alpha/2)))
  }
  
  # return
  return(list('CIs' = bootCI, 'betas' = betaCI))
}